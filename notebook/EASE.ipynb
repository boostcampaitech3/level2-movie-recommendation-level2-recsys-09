{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6245ffd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System version: 3.8.5 (default, Sep  4 2020, 07:30:14) \n",
      "[GCC 7.3.0]\n",
      "Pandas version: 1.4.1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "from tqdm import tqdm\n",
    "\n",
    "from recommenders.utils.timer import Timer\n",
    "from recommenders.datasets.split_utils import min_rating_filter_pandas\n",
    "from recommenders.datasets.python_splitters import numpy_stratified_split\n",
    "from recommenders.evaluation.python_evaluation import map_at_k, ndcg_at_k, precision_at_k, recall_at_k\n",
    "from recommenders.datasets.pandas_df_utils import filter_by, negative_feedback_sampler\n",
    "from recommenders.datasets.python_splitters import python_stratified_split\n",
    "\n",
    "print(\"System version: {}\".format(sys.version))\n",
    "print(\"Pandas version: {}\".format(pd.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73258f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.sparse import csr_matrix\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# from tqdm import tqdm\n",
    "\n",
    "\n",
    "# class EASE:\n",
    "#     def __init__(self):\n",
    "#         self.user_enc = LabelEncoder()\n",
    "#         self.item_enc = LabelEncoder()\n",
    "\n",
    "#     def _get_users_and_items(self, df):\n",
    "#         users = self.user_enc.fit_transform(df.loc[:, 'userID'])\n",
    "#         items = self.item_enc.fit_transform(df.loc[:, 'itemID'])\n",
    "#         return users, items\n",
    "\n",
    "#     def fit(self, df, lambda_: float = 0.5, implicit=True):\n",
    "#         \"\"\"\n",
    "#         df: pandas.DataFrame with columns user_id, item_id and (rating)\n",
    "#         lambda_: l2-regularization term\n",
    "#         implicit: if True, ratings are ignored and taken as 1, else normalized ratings are used\n",
    "#         \"\"\"\n",
    "#         users, items = self._get_users_and_items(df)\n",
    "#         values = np.ones(df.shape[0]) if implicit else df['rating'].to_numpy() / df['rating'].max()\n",
    "\n",
    "#         X = csr_matrix((values, (users, items)))\n",
    "#         self.X = X\n",
    "\n",
    "#         G = X.T.dot(X).toarray()\n",
    "#         diagIndices = np.diag_indices(G.shape[0])\n",
    "#         G[diagIndices] += lambda_\n",
    "#         P = np.linalg.inv(G)\n",
    "#         B = P / (-np.diag(P))\n",
    "#         B[diagIndices] = 0\n",
    "\n",
    "#         self.B = B\n",
    "#         self.pred = X.dot(B)\n",
    "\n",
    "#     def predict(self, train, users, items, k):\n",
    "#         df = pd.DataFrame()\n",
    "#         items = self.item_enc.transform(items)\n",
    "#         dd = train.loc[train.userID.isin(users)]\n",
    "#         dd['ci'] = self.item_enc.transform(dd.itemID)\n",
    "#         dd['cu'] = self.user_enc.transform(dd.userID)\n",
    "#         g = dd.groupby('userID')\n",
    "#         for user, group in tqdm(g):\n",
    "#             watched = set(group['ci'])\n",
    "#             candidates = [item for item in items if item not in watched]\n",
    "#             u = group['cu'].iloc[0]\n",
    "#             pred = np.take(self.pred[u, :], candidates)\n",
    "#             res = np.argpartition(pred, -k)[-k:]\n",
    "#             r = pd.DataFrame({\n",
    "#                 \"userID\": [user] * len(res),\n",
    "#                 \"itemID\": np.take(candidates, res),\n",
    "#                 \"score\": np.take(pred, res)\n",
    "#             }).sort_values('score', ascending=False)\n",
    "#             df = df.append(r, ignore_index=True)\n",
    "#         df['itemID'] = self.item_enc.inverse_transform(df['itemID'])\n",
    "#         return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "345491f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "import scipy.sparse as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class EASE:\n",
    "    def __init__(self):\n",
    "        self.user_enc = LabelEncoder()\n",
    "        self.item_enc = LabelEncoder()\n",
    "\n",
    "    def _get_users_and_items(self, df):\n",
    "        users = self.user_enc.fit_transform(df.loc[:, 'userID'])\n",
    "        items = self.item_enc.fit_transform(df.loc[:, 'itemID'])\n",
    "        return users, items\n",
    "\n",
    "    def fit(self, df, lambda_: float = 0.5, implicit=True):\n",
    "        \"\"\"\n",
    "        df: pandas.DataFrame with columns user_id, item_id and (rating)\n",
    "        lambda_: l2-regularization term\n",
    "        implicit: if True, ratings are ignored and taken as 1, else normalized ratings are used\n",
    "        \"\"\"\n",
    "        users, items = self._get_users_and_items(df)\n",
    "        values = np.ones(df.shape[0]) if implicit else df['rating'].to_numpy() / df['rating'].max()\n",
    "\n",
    "        X = csr_matrix((values, (users, items))).astype(np.float32)\n",
    "        self.X = X\n",
    "\n",
    "        G = X.T.dot(X).toarray()\n",
    "        diagIndices = np.diag_indices(G.shape[0])\n",
    "        G[diagIndices] += lambda_\n",
    "        P = np.linalg.inv(G)\n",
    "        B = P / (-np.diag(P))\n",
    "        B[diagIndices] = 0\n",
    "#         reg_weight = 250.\n",
    "\n",
    "#         G = X.T @ X\n",
    "\n",
    "#         # add reg to diagonal\n",
    "#         G += reg_weight * sp.identity(G.shape[0])\n",
    "\n",
    "#         # convert to dense because inverse will be dense\n",
    "#         G = G.todense()\n",
    "\n",
    "#         # invert. this takes most of the time\n",
    "#         P = np.linalg.inv(G)\n",
    "#         B = P / (-np.diag(P))\n",
    "#         # zero out diag\n",
    "#         np.fill_diagonal(B, 0.)\n",
    "\n",
    "        self.B = B\n",
    "        self.pred = X.dot(B)\n",
    "\n",
    "    def predict(self, train, users, items, k):\n",
    "        df = pd.DataFrame()\n",
    "        items = self.item_enc.transform(items)\n",
    "        dd = train.loc[train.userID.isin(users)]\n",
    "        dd['ci'] = self.item_enc.transform(dd.itemID)\n",
    "        dd['cu'] = self.user_enc.transform(dd.userID)\n",
    "        g = dd.groupby('userID')\n",
    "        for user, group in tqdm(g):\n",
    "            watched = set(group['ci'])\n",
    "            last_year = group['rated_year'].max()\n",
    "            years = dd[dd['year'] > last_year]['ci'].unique()\n",
    "            watched.update(years)\n",
    "            candidates = [item for item in items if item not in watched]\n",
    "            u = group['cu'].iloc[0]\n",
    "            pred = np.take(self.pred[u, :], candidates)\n",
    "            res = np.argpartition(pred, -k)[-k:]\n",
    "            r = pd.DataFrame({\n",
    "                \"userID\": [user] * len(res),\n",
    "                \"itemID\": np.take(candidates, res),\n",
    "                \"score\": np.take(pred, res)\n",
    "            }).sort_values('score', ascending=False)\n",
    "            df = df.append(r, ignore_index=True)\n",
    "        df['itemID'] = self.item_enc.inverse_transform(df['itemID'])\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8de72eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "import scipy.sparse as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class EASE:\n",
    "    def __init__(self):\n",
    "        self.user_enc = LabelEncoder()\n",
    "        self.item_enc = LabelEncoder()\n",
    "\n",
    "    def _get_users_and_items(self, df):\n",
    "        users = self.user_enc.fit_transform(df.loc[:, 'userID'])\n",
    "        items = self.item_enc.fit_transform(df.loc[:, 'itemID'])\n",
    "        return users, items\n",
    "\n",
    "    def fit(self, df, lambda_: float = 0.5, implicit=True):\n",
    "        \"\"\"\n",
    "        df: pandas.DataFrame with columns user_id, item_id and (rating)\n",
    "        lambda_: l2-regularization term\n",
    "        implicit: if True, ratings are ignored and taken as 1, else normalized ratings are used\n",
    "        \"\"\"\n",
    "        users, items = self._get_users_and_items(df)\n",
    "        values = np.ones(df.shape[0]) if implicit else df['rating'].to_numpy() / df['rating'].max()\n",
    "\n",
    "        X = csr_matrix((values, (users, items)))\n",
    "        self.X = X\n",
    "\n",
    "        reg_weight = 250.\n",
    "\n",
    "        G = X.T @ X\n",
    "\n",
    "        # add reg to diagonal\n",
    "        G += reg_weight * sp.identity(G.shape[0])\n",
    "\n",
    "        # convert to dense because inverse will be dense\n",
    "        G = G.todense()\n",
    "\n",
    "        # invert. this takes most of the time\n",
    "        P = np.linalg.inv(G)\n",
    "        B = P / (-np.diag(P))\n",
    "        # zero out diag\n",
    "        np.fill_diagonal(B, 0.)\n",
    "\n",
    "        self.B = B\n",
    "        self.pred = X.dot(B)\n",
    "\n",
    "    def predict(self, train, users, items, k):\n",
    "        df = pd.DataFrame()\n",
    "        items = self.item_enc.transform(items)\n",
    "        dd = train.loc[train.userID.isin(users)]\n",
    "        dd['ci'] = self.item_enc.transform(dd.itemID)\n",
    "        dd['cu'] = self.user_enc.transform(dd.userID)\n",
    "        g = dd.groupby('userID')\n",
    "        for user, group in tqdm(g):\n",
    "            watched = set(group['ci'])\n",
    "            candidates = [item for item in items if item not in watched]\n",
    "            u = group['cu'].iloc[0]\n",
    "            pred = np.take(self.pred[u, :], candidates)\n",
    "            res = np.argpartition(pred, -k)[-k:]\n",
    "            r = pd.DataFrame({\n",
    "                \"userID\": [user] * len(res),\n",
    "                \"itemID\": np.take(candidates, res),\n",
    "                \"score\": np.take(pred, res)\n",
    "            }).sort_values('score', ascending=False)\n",
    "            df = df.append(r, ignore_index=True)\n",
    "        df['itemID'] = self.item_enc.inverse_transform(df['itemID'])\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed9afd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# top k items to recommend\n",
    "TOP_K = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6151148a",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcc98381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>4643</td>\n",
       "      <td>1230782529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>170</td>\n",
       "      <td>1230782534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>531</td>\n",
       "      <td>1230782539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>616</td>\n",
       "      <td>1230782542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>2140</td>\n",
       "      <td>1230782563</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  itemID   timestamp\n",
       "0      11    4643  1230782529\n",
       "1      11     170  1230782534\n",
       "2      11     531  1230782539\n",
       "3      11     616  1230782542\n",
       "4      11    2140  1230782563"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COL_USER = \"userID\"\n",
    "COL_ITEM = \"itemID\"\n",
    "COL_RATING = \"rating\"\n",
    "COL_PREDICTION = \"rating\"\n",
    "COL_TIMESTAMP = \"timestamp\"\n",
    "\n",
    "root_dir = '/opt/ml/input/data/train/'\n",
    "df = pd.read_csv(os.path.join(root_dir,'train_ratings.csv'), names=[COL_USER, COL_ITEM, COL_TIMESTAMP], header=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1c08301",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rating'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9fdd576",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5154471/5154471 [00:07<00:00, 712179.77it/s]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "df['rated_year'] = df['timestamp'].progress_apply(lambda x: date.fromtimestamp(x).year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e4514f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>rating</th>\n",
       "      <th>rated_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>4643</td>\n",
       "      <td>1230782529</td>\n",
       "      <td>1</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>170</td>\n",
       "      <td>1230782534</td>\n",
       "      <td>1</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>531</td>\n",
       "      <td>1230782539</td>\n",
       "      <td>1</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>616</td>\n",
       "      <td>1230782542</td>\n",
       "      <td>1</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>2140</td>\n",
       "      <td>1230782563</td>\n",
       "      <td>1</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5154466</th>\n",
       "      <td>138493</td>\n",
       "      <td>44022</td>\n",
       "      <td>1260209449</td>\n",
       "      <td>1</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5154467</th>\n",
       "      <td>138493</td>\n",
       "      <td>4958</td>\n",
       "      <td>1260209482</td>\n",
       "      <td>1</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5154468</th>\n",
       "      <td>138493</td>\n",
       "      <td>68319</td>\n",
       "      <td>1260209720</td>\n",
       "      <td>1</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5154469</th>\n",
       "      <td>138493</td>\n",
       "      <td>40819</td>\n",
       "      <td>1260209726</td>\n",
       "      <td>1</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5154470</th>\n",
       "      <td>138493</td>\n",
       "      <td>27311</td>\n",
       "      <td>1260209807</td>\n",
       "      <td>1</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5154471 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         userID  itemID   timestamp  rating  rated_year\n",
       "0            11    4643  1230782529       1        2009\n",
       "1            11     170  1230782534       1        2009\n",
       "2            11     531  1230782539       1        2009\n",
       "3            11     616  1230782542       1        2009\n",
       "4            11    2140  1230782563       1        2009\n",
       "...         ...     ...         ...     ...         ...\n",
       "5154466  138493   44022  1260209449       1        2009\n",
       "5154467  138493    4958  1260209482       1        2009\n",
       "5154468  138493   68319  1260209720       1        2009\n",
       "5154469  138493   40819  1260209726       1        2009\n",
       "5154470  138493   27311  1260209807       1        2009\n",
       "\n",
       "[5154471 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1df4262a",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = pd.read_csv('./years_fixed.tsv', sep='\\t', names=[COL_ITEM, 'year'], header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ffebf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, years, how='left', on='itemID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0bf06749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>rating</th>\n",
       "      <th>rated_year</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>4643</td>\n",
       "      <td>1230782529</td>\n",
       "      <td>1</td>\n",
       "      <td>2009</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>170</td>\n",
       "      <td>1230782534</td>\n",
       "      <td>1</td>\n",
       "      <td>2009</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>531</td>\n",
       "      <td>1230782539</td>\n",
       "      <td>1</td>\n",
       "      <td>2009</td>\n",
       "      <td>1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>616</td>\n",
       "      <td>1230782542</td>\n",
       "      <td>1</td>\n",
       "      <td>2009</td>\n",
       "      <td>1970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>2140</td>\n",
       "      <td>1230782563</td>\n",
       "      <td>1</td>\n",
       "      <td>2009</td>\n",
       "      <td>1982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5154466</th>\n",
       "      <td>138493</td>\n",
       "      <td>44022</td>\n",
       "      <td>1260209449</td>\n",
       "      <td>1</td>\n",
       "      <td>2009</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5154467</th>\n",
       "      <td>138493</td>\n",
       "      <td>4958</td>\n",
       "      <td>1260209482</td>\n",
       "      <td>1</td>\n",
       "      <td>2009</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5154468</th>\n",
       "      <td>138493</td>\n",
       "      <td>68319</td>\n",
       "      <td>1260209720</td>\n",
       "      <td>1</td>\n",
       "      <td>2009</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5154469</th>\n",
       "      <td>138493</td>\n",
       "      <td>40819</td>\n",
       "      <td>1260209726</td>\n",
       "      <td>1</td>\n",
       "      <td>2009</td>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5154470</th>\n",
       "      <td>138493</td>\n",
       "      <td>27311</td>\n",
       "      <td>1260209807</td>\n",
       "      <td>1</td>\n",
       "      <td>2009</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5154471 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         userID  itemID   timestamp  rating  rated_year  year\n",
       "0            11    4643  1230782529       1        2009  2001\n",
       "1            11     170  1230782534       1        2009  1995\n",
       "2            11     531  1230782539       1        2009  1993\n",
       "3            11     616  1230782542       1        2009  1970\n",
       "4            11    2140  1230782563       1        2009  1982\n",
       "...         ...     ...         ...     ...         ...   ...\n",
       "5154466  138493   44022  1260209449       1        2009  2006\n",
       "5154467  138493    4958  1260209482       1        2009  2001\n",
       "5154468  138493   68319  1260209720       1        2009  2009\n",
       "5154469  138493   40819  1260209726       1        2009  2005\n",
       "5154470  138493   27311  1260209807       1        2009  2000\n",
       "\n",
       "[5154471 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e0f9979",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = python_stratified_split(df, ratio=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4b5be5",
   "metadata": {},
   "source": [
    "# EASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f9f4cdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EASE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "03680d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference할 때는 전체 데이터(df)로 학습 필요\n",
    "# evaluation할 때는 train data로만 학습\n",
    "model.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c2be2c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "users = df['userID'].unique()\n",
    "items = df['itemID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d53e6f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31360 6807\n"
     ]
    }
   ],
   "source": [
    "print(len(users), len(items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4631733c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31360, 6807)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ea40c5",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fbb7f89a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/31360 [00:00<?, ?it/s]/tmp/ipykernel_34622/433780093.py:77: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(r, ignore_index=True)\n",
      "  0%|          | 71/31360 [00:03<25:38, 20.34it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [43]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# inference할 때는 전체 데이터(df)로 inference 필요\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# evaluation할 때는 train data로 inference\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43musers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitems\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [37]\u001b[0m, in \u001b[0;36mEASE.predict\u001b[0;34m(self, train, users, items, k)\u001b[0m\n\u001b[1;32m     64\u001b[0m watched \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mci\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     65\u001b[0m last_year \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrated_year\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmax()\n\u001b[0;32m---> 66\u001b[0m years \u001b[38;5;241m=\u001b[39m \u001b[43mdd\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdd\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43myear\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlast_year\u001b[49m\u001b[43m]\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mci\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique()\n\u001b[1;32m     67\u001b[0m watched\u001b[38;5;241m.\u001b[39mupdate(years)\n\u001b[1;32m     68\u001b[0m candidates \u001b[38;5;241m=\u001b[39m [item \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m items \u001b[38;5;28;01mif\u001b[39;00m item \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m watched]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/frame.py:3496\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3494\u001b[0m \u001b[38;5;66;03m# Do we have a (boolean) 1d indexer?\u001b[39;00m\n\u001b[1;32m   3495\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m com\u001b[38;5;241m.\u001b[39mis_bool_indexer(key):\n\u001b[0;32m-> 3496\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_bool_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3498\u001b[0m \u001b[38;5;66;03m# We are left with two options: a single key, and a collection of keys,\u001b[39;00m\n\u001b[1;32m   3499\u001b[0m \u001b[38;5;66;03m# We interpret tuples as collections only for non-MultiIndex\u001b[39;00m\n\u001b[1;32m   3500\u001b[0m is_single_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_list_like(key)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/frame.py:3551\u001b[0m, in \u001b[0;36mDataFrame._getitem_bool_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3549\u001b[0m key \u001b[38;5;241m=\u001b[39m check_bool_indexer(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, key)\n\u001b[1;32m   3550\u001b[0m indexer \u001b[38;5;241m=\u001b[39m key\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m-> 3551\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_with_is_copy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/generic.py:3728\u001b[0m, in \u001b[0;36mNDFrame._take_with_is_copy\u001b[0;34m(self, indices, axis)\u001b[0m\n\u001b[1;32m   3720\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_take_with_is_copy\u001b[39m(\u001b[38;5;28mself\u001b[39m: NDFrameT, indices, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NDFrameT:\n\u001b[1;32m   3721\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3722\u001b[0m \u001b[38;5;124;03m    Internal version of the `take` method that sets the `_is_copy`\u001b[39;00m\n\u001b[1;32m   3723\u001b[0m \u001b[38;5;124;03m    attribute to keep track of the parent dataframe (using in indexing\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3726\u001b[0m \u001b[38;5;124;03m    See the docstring of `take` for full explanation of the parameters.\u001b[39;00m\n\u001b[1;32m   3727\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3728\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3729\u001b[0m     \u001b[38;5;66;03m# Maybe set copy if we didn't actually change the index.\u001b[39;00m\n\u001b[1;32m   3730\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result\u001b[38;5;241m.\u001b[39m_get_axis(axis)\u001b[38;5;241m.\u001b[39mequals(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis(axis)):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/generic.py:3715\u001b[0m, in \u001b[0;36mNDFrame.take\u001b[0;34m(self, indices, axis, is_copy, **kwargs)\u001b[0m\n\u001b[1;32m   3711\u001b[0m nv\u001b[38;5;241m.\u001b[39mvalidate_take((), kwargs)\n\u001b[1;32m   3713\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consolidate_inplace()\n\u001b[0;32m-> 3715\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_block_manager_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m   3717\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3718\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor(new_data)\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtake\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/internals/managers.py:899\u001b[0m, in \u001b[0;36mBaseBlockManager.take\u001b[0;34m(self, indexer, axis, verify)\u001b[0m\n\u001b[1;32m    896\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape[axis]\n\u001b[1;32m    897\u001b[0m indexer \u001b[38;5;241m=\u001b[39m maybe_convert_indices(indexer, n, verify\u001b[38;5;241m=\u001b[39mverify)\n\u001b[0;32m--> 899\u001b[0m new_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maxes\u001b[49m\u001b[43m[\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreindex_indexer(\n\u001b[1;32m    901\u001b[0m     new_axis\u001b[38;5;241m=\u001b[39mnew_labels,\n\u001b[1;32m    902\u001b[0m     indexer\u001b[38;5;241m=\u001b[39mindexer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    905\u001b[0m     consolidate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    906\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/indexes/base.py:1113\u001b[0m, in \u001b[0;36mIndex.take\u001b[0;34m(self, indices, axis, allow_fill, fill_value, **kwargs)\u001b[0m\n\u001b[1;32m   1111\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m   1112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m-> 1113\u001b[0m     taken \u001b[38;5;241m=\u001b[39m \u001b[43malgos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_fill\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_na_value\u001b[49m\n\u001b[1;32m   1115\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1116\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1117\u001b[0m     \u001b[38;5;66;03m# algos.take passes 'axis' keyword which not all EAs accept\u001b[39;00m\n\u001b[1;32m   1118\u001b[0m     taken \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mtake(\n\u001b[1;32m   1119\u001b[0m         indices, allow_fill\u001b[38;5;241m=\u001b[39mallow_fill, fill_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_na_value\n\u001b[1;32m   1120\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/algorithms.py:1445\u001b[0m, in \u001b[0;36mtake\u001b[0;34m(arr, indices, axis, allow_fill, fill_value)\u001b[0m\n\u001b[1;32m   1440\u001b[0m     result \u001b[38;5;241m=\u001b[39m take_nd(\n\u001b[1;32m   1441\u001b[0m         arr, indices, axis\u001b[38;5;241m=\u001b[39maxis, allow_fill\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, fill_value\u001b[38;5;241m=\u001b[39mfill_value\n\u001b[1;32m   1442\u001b[0m     )\n\u001b[1;32m   1443\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1444\u001b[0m     \u001b[38;5;66;03m# NumPy style\u001b[39;00m\n\u001b[0;32m-> 1445\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43marr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1446\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# inference할 때는 전체 데이터(df)로 inference 필요\n",
    "# evaluation할 때는 train data로 inference\n",
    "predictions = model.predict(train, users, items, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b4ae82",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "d638cc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predictions.rename({\"score\": \"prediction\"}, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba15057",
   "metadata": {},
   "source": [
    "### 연도 + 1 이후로 추천"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "9455dbc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@K:\t0.126524\n"
     ]
    }
   ],
   "source": [
    "eval_recall = recall_at_k(test, predictions, k=TOP_K)\n",
    "print(\"Recall@K:\\t%f\" % eval_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734a5131",
   "metadata": {},
   "source": [
    "### 해당 연도 이후 추천 안함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "293e5a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@K:\t0.126577\n"
     ]
    }
   ],
   "source": [
    "eval_recall = recall_at_k(test, predictions, k=TOP_K)\n",
    "print(\"Recall@K:\\t%f\" % eval_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0119573",
   "metadata": {},
   "source": [
    "### 연도 상관없이 다 추천"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e3749ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@K:\t0.126496\n"
     ]
    }
   ],
   "source": [
    "eval_recall = recall_at_k(test, predictions, k=TOP_K)\n",
    "print(\"Recall@K:\\t%f\" % eval_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1440b46",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "adc932e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_112943/2061835457.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  submission_df.rename(columns = {\"userID\": \"user\", \"itemID\": \"item\"}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "submission_df = predictions[['userID', 'itemID']]\n",
    "submission_df.rename(columns = {\"userID\": \"user\", \"itemID\": \"item\"}, inplace=True)\n",
    "submission_df.to_csv('/opt/ml/input/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb208952",
   "metadata": {},
   "source": [
    "# Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f555c491",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                       | 0/31360 [00:00<?, ?it/s]/tmp/ipykernel_7314/2418120602.py:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(r, ignore_index=True)\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 31360/31360 [10:56<00:00, 47.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda: 0.1 / Recall@K:\t0.12586906030068523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                       | 0/31360 [00:00<?, ?it/s]/tmp/ipykernel_7314/2418120602.py:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(r, ignore_index=True)\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 31360/31360 [11:13<00:00, 46.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda: 0.3 / Recall@K:\t0.12616284261738195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                       | 0/31360 [00:00<?, ?it/s]/tmp/ipykernel_7314/2418120602.py:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(r, ignore_index=True)\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 31360/31360 [10:53<00:00, 47.97it/s]\n",
      " 21%|████████████████████████████████▊                                                                                                                           | 6591/31360 [02:13<08:38, 47.79it/s]"
     ]
    }
   ],
   "source": [
    "df['rating'] = 1\n",
    "hyperparameter = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "for param in hyperparameter:\n",
    "    model = EASE()\n",
    "    model.fit(train, lambda_=param)\n",
    "    predictions = model.predict(train, users, items, 10)\n",
    "    predictions = predictions.rename({\"score\": \"prediction\"}, axis=1)\n",
    "    eval_recall = recall_at_k(test, predictions, k=TOP_K)\n",
    "    print(\"Lambda: {} / Recall@K:\\t{}\".format(param, eval_recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a63e4f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
